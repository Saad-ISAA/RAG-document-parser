#!/usr/bin/env python3
"""
Enhanced Bilingual Document Parser - Comprehensive Example Usage
Demonstrates all features optimized for Arabic/English bilingual document processing.
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Any

# Add the parser to the path
sys.path.append(str(Path(__file__).parent))

from main import UniversalDocumentParser
from utils.config import ParserConfig, OCRConfig, PDFConfig, PowerPointConfig, DocumentConfig, ConverterConfig
from models.parse_result import ParseResult


def create_bilingual_config() -> ParserConfig:
    """Create bilingual-optimized configuration for Arabic/English document processing."""
    print("ğŸŒ Creating bilingual-optimized configuration...")
    
    # OCR configuration for Arabic/English
    ocr_config = OCRConfig(
        enabled=True,
        languages=["ar", "en"],  # Arabic and English
        engine="easyocr",
        confidence_threshold=0.25,  # Lower threshold for Arabic
        arabic_support=True,
        rtl_support=True,
        mixed_language_detection=True,
        preprocessing=True
    )
    
    # PDF configuration
    pdf_config = PDFConfig(
        prefer_pdfplumber=True,
        extract_tables=True,
        extract_images=True
    )
    
    # PowerPoint configuration
    powerpoint_config = PowerPointConfig(
        extract_tables=True,
        extract_images=True,
        extract_slide_notes=True,
        ocr_on_images=True,
        max_slides=200
    )
    
    # Document configuration
    document_config = DocumentConfig(
        extract_tables=True,
        extract_images=True,
        enhanced_doc_parsing=True,
        enable_conversion_fallback=True
    )
    
    # Converter configuration
    converter_config = ConverterConfig(
        enable_online=False,
        libreoffice_timeout=120,
        prefer_local_conversion=True,
        cleanup_temp_files=True
    )
    
    # Main configuration
    config = ParserConfig(
        enable_ocr=True,
        arabic_support=True,
        mixed_language_support=True,
        comprehensive_parsing=True,
        parallel_processing=True,
        max_workers=4,
        max_file_size=200 * 1024 * 1024,  # 200MB
        
        ocr=ocr_config,
        pdf=pdf_config,
        powerpoint=powerpoint_config,
        document=document_config,
        converter=converter_config
    )
    
    print("âœ… Bilingual configuration created successfully!")
    return config


def demonstrate_arabic_text_processing():
    """Demonstrate Arabic text processing capabilities."""
    print("\n" + "="*60)
    print("ğŸ”¤ ARABIC TEXT PROCESSING DEMONSTRATION")
    print("="*60)
    
    # Sample Arabic text
    arabic_samples = [
        "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø·ÙˆØ±",
        "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "Mixed Arabic Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ and English text",
        "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© - Modern Technology"
    ]
    
    config = create_bilingual_config()
    
    # Test Arabic text processing
    try:
        # Check if Arabic reshaping is available
        try:
            import arabic_reshaper
            from bidi.algorithm import get_display
            arabic_support = True
            print("âœ… Arabic text processing libraries available")
        except ImportError:
            arabic_support = False
            print("âš ï¸  Arabic text processing libraries not installed")
            print("   Install with: pip install arabic-reshaper python-bidi")
        
        for i, text in enumerate(arabic_samples, 1):
            print(f"\n--- Sample {i} ---")
            print(f"Original: {text}")
            
            if arabic_support:
                # Process Arabic text
                reshaped = arabic_reshaper.reshape(text)
                display_text = get_display(reshaped)
                print(f"Processed: {display_text}")
            
            # Detect language composition
            arabic_chars = sum(1 for c in text if '\u0600' <= c <= '\u06FF')
            latin_chars = sum(1 for c in text if c.isalpha() and not ('\u0600' <= c <= '\u06FF'))
            
            if arabic_chars > latin_chars:
                lang_type = "Primarily Arabic"
            elif latin_chars > arabic_chars:
                lang_type = "Primarily English"
            else:
                lang_type = "Mixed Arabic/English"
            
            print(f"Language: {lang_type} (Arabic: {arabic_chars}, Latin: {latin_chars})")
    
    except Exception as e:
        print(f"âŒ Arabic processing demonstration failed: {e}")


def demonstrate_powerpoint_parsing():
    """Demonstrate PowerPoint parsing with bilingual support."""
    print("\n" + "="*60)
    print("ğŸ“Š POWERPOINT PARSING DEMONSTRATION")
    print("="*60)
    
    config = create_bilingual_config()
    parser = UniversalDocumentParser(config)
    
    # Look for PowerPoint files
    ppt_extensions = ['*.pptx', '*.ppt']
    ppt_files = []
    
    for pattern in ppt_extensions:
        ppt_files.extend(Path('.').glob(pattern))
    
    if not ppt_files:
        print("â„¹ï¸  No PowerPoint files found in current directory")
        print("   Create a sample PPTX file to test this feature")
        
        # Show what PowerPoint parsing can do
        print("\nğŸ¯ PowerPoint Parsing Capabilities:")
        print("   âœ… Extract text from all slides")
        print("   âœ… Parse tables in presentations")
        print("   âœ… OCR text from images in slides")
        print("   âœ… Handle Arabic/English mixed content")
        print("   âœ… Convert legacy PPT files")
        print("   âœ… Preserve slide structure")
        return
    
    for ppt_file in ppt_files[:2]:  # Test first 2 files
        print(f"\nğŸ“Š Processing: {ppt_file.name}")
        
        try:
            result = parser.parse_file(ppt_file)
            
            if result.success:
                print(f"   âœ… Success with {result.parser_used}")
                print(f"   ğŸ“ Content length: {len(result.content)} characters")
                print(f"   ğŸ“Š Tables found: {len(result.tables)}")
                print(f"   ğŸ–¼ï¸  Images processed: {len(result.images)}")
                
                # Analyze slides
                slides = result.content.split('=== Slide ')
                print(f"   ğŸ“„ Slides detected: {len(slides) - 1}")
                
                # Show first slide preview
                if len(slides) > 1:
                    first_slide = slides[1].split('\n')[:3]
                    print(f"   ğŸ“– First slide preview:")
                    for line in first_slide:
                        if line.strip():
                            print(f"      {line.strip()[:80]}...")
                
                # Check for Arabic content
                arabic_found = any('\u0600' <= char <= '\u06FF' for char in result.content)
                print(f"   ğŸ”¤ Arabic content: {'Yes' if arabic_found else 'No'}")
                
                # Show OCR results
                ocr_results = [img for img in result.images if img.extracted_text]
                if ocr_results:
                    print(f"   ğŸ” OCR extracted text from {len(ocr_results)} images")
                    for img in ocr_results[:2]:  # Show first 2
                        preview = img.extracted_text[:100].replace('\n', ' ')
                        print(f"      Image {img.image_index}: {preview}...")
            
            else:
                print(f"   âŒ Failed: {result.error}")
        
        except Exception as e:
            print(f"   âŒ Error processing {ppt_file.name}: {e}")


def demonstrate_enhanced_doc_parsing():
    """Demonstrate enhanced DOC file parsing."""
    print("\n" + "="*60)
    print("ğŸ“„ ENHANCED DOC PARSING DEMONSTRATION")
    print("="*60)
    
    config = create_bilingual_config()
    parser = UniversalDocumentParser(config)
    
    # Look for DOC files
    doc_files = list(Path('.').glob('*.doc')) + list(Path('.').glob('*.docx'))
    
    if not doc_files:
        print("â„¹ï¸  No DOC/DOCX files found in current directory")
        print("\nğŸ¯ Enhanced DOC Parsing Features:")
        print("   âœ… Mammoth library for better DOC parsing")
        print("   âœ… Conversion fallback (DOC â†’ PDF â†’ Parse)")
        print("   âœ… Multiple extraction methods")
        print("   âœ… Arabic text processing")
        print("   âœ… Image OCR extraction")
        print("   âœ… Table structure preservation")
        return
    
    for doc_file in doc_files[:3]:  # Test first 3 files
        print(f"\nğŸ“„ Processing: {doc_file.name}")
        
        try:
            result = parser.parse_file(doc_file)
            
            if result.success:
                print(f"   âœ… Success with {result.parser_used}")
                print(f"   ğŸ“ Content: {len(result.content)} chars")
                print(f"   ğŸ“Š Tables: {len(result.tables)}")
                print(f"   ğŸ–¼ï¸  Images: {len(result.images)}")
                print(f"   â±ï¸  Time: {result.parsing_time:.2f}s")
                
                # Language analysis
                if result.content:
                    arabic_chars = sum(1 for c in result.content if '\u0600' <= c <= '\u06FF')
                    total_chars = len(result.content)
                    arabic_percentage = (arabic_chars / total_chars * 100) if total_chars > 0 else 0
                    
                    print(f"   ğŸ”¤ Arabic content: {arabic_percentage:.1f}%")
                    
                    # Show content preview
                    preview = result.content[:150].replace('\n', ' ')
                    print(f"   ğŸ“– Preview: {preview}...")
                
                # Show table information
                for i, table in enumerate(result.tables[:2]):  # First 2 tables
                    print(f"   ğŸ“Š Table {i+1}: {len(table.headers)} cols Ã— {len(table.rows)} rows")
                    if table.headers:
                        headers_preview = ', '.join(table.headers[:3])
                        print(f"      Headers: {headers_preview}...")
            
            else:
                print(f"   âŒ Failed: {result.error}")
                
                # If it's a DOC file, explain the enhanced parsing attempt
                if doc_file.suffix.lower() == '.doc':
                    print("   â„¹ï¸  DOC files use enhanced parsing with multiple fallback methods")
        
        except Exception as e:
            print(f"   âŒ Error: {e}")


def demonstrate_conversion_fallback():
    """Demonstrate conversion fallback for unsupported formats."""
    print("\n" + "="*60)
    print("ğŸ”„ CONVERSION FALLBACK DEMONSTRATION")
    print("="*60)
    
    config = create_bilingual_config()
    parser = UniversalDocumentParser(config)
    
    # Check converter availability
    if hasattr(parser, 'converter') and parser.converter:
        print("âœ… Document converter available")
        
        # Show supported conversions
        try:
            conversions = parser.converter.get_supported_conversions()
            print("\nğŸ”„ Supported conversions:")
            for target, formats in conversions.items():
                if formats:
                    print(f"   {target}: {', '.join(formats)}")
        except Exception as e:
            print(f"   âš ï¸  Could not get conversion info: {e}")
    else:
        print("âš ï¸  Document converter not available")
        print("   Install LibreOffice or enable Office automation for conversion support")
        return
    
    # Look for files that might need conversion
    conversion_candidates = []
    for ext in ['.ppt', '.doc']:
        conversion_candidates.extend(Path('.').glob(f'*{ext}'))
    
    if conversion_candidates:
        print(f"\nğŸ“ Found {len(conversion_candidates)} files that might benefit from conversion:")
        
        for file_path in conversion_candidates[:2]:  # Test first 2
            print(f"\nğŸ”„ Testing conversion for: {file_path.name}")
            
            try:
                result = parser.parse_file(file_path)
                
                if result.success:
                    if 'conversion' in result.parser_used:
                        print(f"   âœ… Successfully converted and parsed with {result.parser_used}")
                        print(f"   ğŸ“ Extracted {len(result.content)} characters")
                    else:
                        print(f"   âœ… Parsed directly with {result.parser_used}")
                else:
                    print(f"   âŒ Conversion and parsing failed: {result.error}")
                    
            except Exception as e:
                print(f"   âŒ Error: {e}")
    else:
        print("\nâ„¹ï¸  No files found that typically require conversion (.ppt, .doc)")


def comprehensive_batch_analysis():
    """Perform comprehensive analysis of all documents in directory."""
    print("\n" + "="*60)
    print("ğŸ“Š COMPREHENSIVE BATCH ANALYSIS")
    print("="*60)
    
    config = create_bilingual_config()
    parser = UniversalDocumentParser(config)
    
    print("ğŸ” Scanning current directory for all supported documents...")
    
    # Find all supported files
    supported_extensions = [
        '*.pdf', '*.docx', '*.doc', '*.pptx', '*.ppt',
        '*.xlsx', '*.xls', '*.csv', '*.txt', '*.md',
        '*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp'
    ]
    
    all_files = []
    for pattern in supported_extensions:
        files = list(Path('.').glob(pattern))
        all_files.extend(files)
    
    if not all_files:
        print("â„¹ï¸  No supported documents found in current directory")
        return
    
    print(f"ğŸ“ Found {len(all_files)} supported files")
    
    # Process files (limit to first 10 for demo)
    files_to_process = all_files[:10]
    results = []
    
    print(f"\nğŸš€ Processing {len(files_to_process)} files...")
    
    start_time = time.time()
    
    for i, file_path in enumerate(files_to_process, 1):
        print(f"[{i}/{len(files_to_process)}] Processing {file_path.name}...", end=' ')
        
        try:
            result = parser.parse_file(file_path)
            results.append(result)
            
            if result.success:
                print(f"âœ… ({result.parser_used})")
            else:
                print(f"âŒ ({result.error[:50]}...)")
                
        except Exception as e:
            print(f"âŒ (Exception: {str(e)[:50]}...)")
    
    processing_time = time.time() - start_time
    
    # Generate comprehensive report
    print(f"\nğŸ“Š BATCH PROCESSING REPORT")
    print(f"â±ï¸  Total time: {processing_time:.2f} seconds")
    print(f"ğŸ“ˆ Average time per file: {processing_time/len(files_to_process):.2f}s")
    
    # Success statistics
    successful = [r for r in results if r.success]
    print(f"âœ… Success rate: {len(successful)}/{len(results)} ({len(successful)/len(results)*100:.1f}%)")
    
    # Parser usage statistics
    parser_usage = {}
    for result in successful:
        parser = result.parser_used or 'unknown'
        parser_usage[parser] = parser_usage.get(parser, 0) + 1
    
    if parser_usage:
        print(f"\nğŸ”§ Parser usage:")
        for parser, count in sorted(parser_usage.items(), key=lambda x: x[1], reverse=True):
            print(f"   {parser}: {count} files")
    
    # Content analysis
    arabic_docs = 0
    english_docs = 0
    mixed_docs = 0
    total_tables = 0
    total_images = 0
    ocr_extractions = 0
    
    for result in successful:
        if result.content:
            # Language analysis
            arabic_chars = sum(1 for c in result.content if '\u0600' <= c <= '\u06FF')
            latin_chars = sum(1 for c in result.content if c.isalpha() and not ('\u0600' <= c <= '\u06FF'))
            
            if arabic_chars > latin_chars * 2:
                arabic_docs += 1
            elif latin_chars > arabic_chars * 2:
                english_docs += 1
            else:
                mixed_docs += 1
        
        # Structure analysis
        total_tables += len(result.tables)
        total_images += len(result.images)
        
        # OCR analysis
        if any(img.extracted_text for img in result.images):
            ocr_extractions += 1
    
    print(f"\nğŸŒ Language Analysis:")
    print(f"   ğŸ”¤ Primarily Arabic: {arabic_docs}")
    print(f"   ğŸ”¤ Primarily English: {english_docs}")
    print(f"   ğŸŒ Mixed language: {mixed_docs}")
    
    print(f"\nğŸ“Š Content Extraction:")
    print(f"   ğŸ“‹ Tables extracted: {total_tables}")
    print(f"   ğŸ–¼ï¸  Images processed: {total_images}")
    print(f"   ğŸ” OCR extractions: {ocr_extractions}")
    
    # File type breakdown
    file_types = {}
    for result in results:
        ext = Path(result.file_path).suffix.lower()
        file_types[ext] = file_types.get(ext, {'total': 0, 'success': 0})
        file_types[ext]['total'] += 1
        if result.success:
            file_types[ext]['success'] += 1
    
    if file_types:
        print(f"\nğŸ“„ File Type Performance:")
        for ext, stats in sorted(file_types.items()):
            success_rate = stats['success'] / stats['total'] * 100
            print(f"   {ext}: {stats['success']}/{stats['total']} ({success_rate:.0f}%)")


def main():
    """Main demonstration function."""
    print("ğŸŒ ENHANCED BILINGUAL DOCUMENT PARSER - COMPREHENSIVE DEMO")
    print("=" * 70)
    print("Welcome to the enhanced document parser optimized for bilingual processing!")
    print("This demo showcases all features including Arabic/English support, PowerPoint")
    print("parsing, enhanced DOC processing, and conversion capabilities.")
    print("=" * 70)
    
    # Run all demonstrations
    try:
        # 1. Arabic text processing
        demonstrate_arabic_text_processing()
        
        # 2. PowerPoint parsing
        demonstrate_powerpoint_parsing()
        
        # 3. Enhanced DOC parsing
        demonstrate_enhanced_doc_parsing()
        
        # 4. Conversion fallback
        demonstrate_conversion_fallback()
        
        # 5. Comprehensive batch analysis
        comprehensive_batch_analysis()
        
        print("\n" + "="*70)
        print("ğŸ‰ DEMONSTRATION COMPLETE!")
        print("=" * 70)
        print("Your enhanced bilingual document parser is ready for:")
        print("âœ… Arabic/English document processing")
        print("âœ… PowerPoint presentations with OCR")
        print("âœ… Enhanced DOC file parsing")
        print("âœ… Automatic format conversion")
        print("âœ… Batch processing with analytics")
        print("âœ… Enterprise-grade performance")
        print("\nğŸš€ Start using it with your bilingual documents today!")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Demo stopped by user")
    except Exception as e:
        print(f"\nâŒ Demo failed with error: {e}")
        print("Please check your setup and dependencies")


if __name__ == "__main__":
    main()